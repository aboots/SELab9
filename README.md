به نام خدا

# آزمایش نهم آزمایشگاه مهندسی نرم‌افزار (استقرار یک نرم افزار با معماری MicroService به کمک Docker) 
## مقدمات آزمایش
در این آزمایش بیشتر با معماری میکرو سرویس آشنا می‌شویم و سعی می‌کنیم تا یک پروژه‌ی بک‌اند را داکرایز کنیم و با docker و قابلیت‌های آن هم بیشتر آشنا شویم.

## شرح آزمایش

در این آزمایش frameworkای که ما استفاده کرده‌ایم django می‌باشد و پروژه‌ی ساده‌ای به این فریم‌ورک backend تعریف کردیم که صرفا یک مدل Task دارد و یک جورایی برنامه‌ی todo list را پیاده سازی کردیم. با توجه به این که در صورت آزمایش و در کلاس گفته شد که نیازی به پروژه‌ی سنگین نیست و صرفا هدف میکروسرویس بودن و استفاده از داکر می‌باشد از پروژه‌ی نسبتا ساده‌ای به عنوان back-end استفاده کردیم. در این پروژه urlهایی که داریم برای apiهای مختلف به شرح زیر است:
- GET api/v1/todo: لیست تمام تسک‌ها
- POST api/v1/todo: ساخت یک تسک جدید
- GET api/v1/todo/<int:todo_id>/:  گرفتن یک تسک خاص با آیدی آن
- PUT api/v1/todo/<int:todo_id>/: آپدیت یک تسک خاص با آیدی آن
- DELETE api/v1/todo/<int:todo_id>/: حذف یک تسک خاص با آیدی آن

بعد از اتمام کد برنامه که در ریپو موجود است سراغ درست کردن داکر‌فایل‌ها رفتیم. نخست یک داکر فایل مخصوص جنگو برای برنامه‌ی خود نوشتیم که در زیر می‌بینید:

![image](https://github.com/aboots/SELab9/assets/59336942/a312745b-b5f1-4102-86ad-461ab5909058)

حال فایل docker-compose را می‌سازیم که در فایل docker-compose در همین ریپو قابل دیدن است. دو سرویس django و یک سرویس db postgres و یک سرویس nginx (برای لود بالانسینگ) قرار می‌دهیم. دو سرویس آخر از imageهای آماده در سطح دنیا استفاده می‌کند. نکته‌ی مهم این است که برای دو سرویس backend از دو پورت مختلف 8000 و 8001 استفاده کردیم که قابل تفکیک برای nginx باشند. از nginx هم برای لود بالانس بین instanceهای مختلف استفاده می‌کنیم. در زیر UMLای از معماری گفته شده می‌بینید (منتها ما دو سرویس بک‌اند قرار داده‌ایم). که درخواست‌ها به سراغ nginx می‌آیند و سپس تقسیم می‌شوند، و تمام سرویس‌ها stateless هستند و از یک دیتابیس مشترک استفاده می‌کنند.

![image](https://github.com/aboots/SELab9/assets/59336942/65c161db-aeec-4ce0-b2bc-0959b2d29b3d)

در زیر کانفیگ مخصوص nginxمان را مشاهده می‌کنید که در فایل nginx.conf موجود است.

![image](https://github.com/aboots/SELab9/assets/59336942/4ca64694-7746-4d6f-96ec-cbb89a25deca)

نکته: فایل .env برای امنیت در گیت نیست ولی اگر خواستید ران کنید مواردی که درون env برای دیتابیس باید باشد به شرح زیر است:
DEBUG=1
SECRET_KEY=foo
DJANGO_ALLOWED_HOSTS=localhost 127.0.0.1 [::1]
SQL_ENGINE=django.db.backends.postgresql
SQL_DATABASE=hello_django_dev
SQL_USER=hello_django
SQL_PASSWORD=hello_django
SQL_HOST=db
SQL_PORT=5432
حال نوبت این است که docker-compose را build کنیم و سپس آن را اجرا کنیم که در زیر آن را می‌بینید. الان سرویس‌های ما بالا هستند.

![image](https://github.com/aboots/SELab9/assets/59336942/df31672a-0df5-43ee-8f91-d6278a323475)
![image](https://github.com/aboots/SELab9/assets/59336942/5467b6e3-d04f-4a1b-a19d-2431819b5d68)
![image](https://github.com/aboots/SELab9/assets/59336942/b21adb83-39ad-4f7d-980b-dde44edeb6c2)

حال اگر دستور docker ps بزنیم می‌بینیم که 4 container مد نظرمان در حال فعالیت هستند و بالا هستند.

![image](https://github.com/aboots/SELab9/assets/59336942/2aded902-08a3-4179-b8a3-ddf559022139)

در زیر هم دستور docker image ls را می‌زنیم که همانطور که می‌بینید تمام imageهای روی سیستم من را نشان می‌دهد. همانطور که می‌بینید image مربوطه به 4 سرویس مربوطه را می‌بینید.

![image](https://github.com/aboots/SELab9/assets/59336942/6f79a940-2e55-40f0-a941-c0a1b8a25b6a)

حال در مرورگر اگر به آدرس http://127.0.0.1:8000/api/v1/todo برویم می‌بینیم که لیست تسک‌ها را به ما بر می‌گرداند که همانطور که می‌بینید در زیر یک تسک داریم که فیلد‌های آن نظیر name و وضعیت تکمیل و زمان ساخت و ... را می‌بینید. این درخواست به nginx فرستاده شد و همانطور که می‌بینید به درستی به سرویس‌هایمان منتقل شده است. 

![image](https://github.com/aboots/SELab9/assets/59336942/cc4d4466-9036-4a89-b334-f08f5fb428d7)

همانطور که در زیر می‌بینید درخواست فوق به وب‌سرویس اولمان منتقل شده است و پاسخش هم به درستی آمده است. 

![image](https://github.com/aboots/SELab9/assets/59336942/6094f0c4-b310-4d2d-8847-f61a8eb604e5)
حال به سرور اول درخواست مستقیم می‌زنیم و یک post می‌زنیم که یک تسک درست کنیم که همانطور که در زیر می‌بینید از برنامه‌ی postman به درستی درخواست زده شد.

![image](https://github.com/aboots/SELab9/assets/59336942/d4d26e69-ed00-4cf6-9255-7f4b9474423a)

حال از سرور دوم درخواست GET می‌زنیم و همانطور که می‌بینید به درستی پاسخ درخواست برگردانده شد و هر دو تسک در لیست هستند که نشان می‌دهد به درستی هر دو instance به یک دیتابیس وصل هستند.

![image](https://github.com/aboots/SELab9/assets/59336942/a573d25d-e742-4eb8-b07a-66a3044dfb60)

در نهایت برای تست تسکی که ساختیم را آپدیت می‌کنیم. اسم آن را عوض می‌کنیم و وضعیت آن را به انجام شده تغییر می‌دهیم که در زیر می‌بینید.

![image](https://github.com/aboots/SELab9/assets/59336942/c5bc448e-c211-40bf-9c22-c9a26951f130)

حال اگر به پورت nginx درخواست بزنیم و GET کنیم می‌بینیم که تسک جدیدی که ساختیم آپدیت شده است.

![image](https://github.com/aboots/SELab9/assets/59336942/a24948aa-7a5c-424f-88ec-efe0041435d5)

پس با تست سناریو‌های مختلف دیدیم که سرویس به درستی کار می‌کند. توجه کنید nginxای که اضافه کردیم برای load balancing بود. اگر احیانا فشار زیاد بود می‌توانیم یک instance جدید دیگر بالا بیاریم که خیلی ساده است و صرفا به یک port دیگر نیاز داریم و دیگر در این صورت خود nginx درخواست‌ها را به درستی تقسیم می‌کند. برای instance هم تنها چند خط باید در فایل .yml مان و کانفیگ nginx اضافه کنیم.
  web3:
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/code
    ports:
      - "8002:8000"
    depends_on:
      - db
و در کانفیگ nginx:
upstream backend {
  server web:8000;
  server web2:8001;
  server web3:8002;
}

افزایش تعداد instance بک‌اند ساده‌ترین راه برای افزایش ظرفیت سرویس‌های بک‌اند است. با این کار، درخواست‌ها بین چندین instance تقسیم می‌شود و فشار روی هر instance کاهش می‌یابد. البته راه‌های دیگری هم موجود است. حتی می‌توان در تنظیمات compose خود replicas تعریف کنیم. استفاده از caching هم می‌تواند کمک کننده باشد یا استفاده از بعضی ویژگی‌های داکر مثل scale یا حتی بهترین راه استفاده از Kubernetes و سرویس‌های امثال آن است که امروزه در صنعت بسیار استفاده می‌شوند.


## پرسش‌ها

1. مفهوم stateless به چه معناست؟ ما چه استفاده‌ای از این مفهوم در آزمایش خود کرده‌ایم؟

در زمینه Docker و میکروسرویس‌ها، "stateless" به یک سرویس اشاره دارد که هیچ گونه وضعیت یا اطلاعات جلسه را بین درخواست‌ها ذخیره نمی‌کند. هر درخواستی که به یک سرویس stateless ارسال می‌شود، به صورت مستقل تلقی می‌شود، بدون هیچ دانشی از درخواست‌های قبلی پردازش می‌شود. در این آزمایش ما از این استفاده کردیم که چند تا instance داریم ولی چون stateless هستند پس درخواست به هر کدام برود اوکی است و تفاوتی ایجاد نمی‌کند و APIهای ما هر کدام در هر درخواست یک کار واحد را انجام می‌دهند که تاثیرش بر روی دیتابیس و در نتیجه همه‌ی instanceها است. همین ویژگی به ما این امکان را می‌دهد که scaliblity بالا داشته باشیم و مشکلی برای اضافه کردن instanceها نداشته باشیم. برای همین می‌توانیم تعداد را زیاد و کم کنیم و coupling کم می‌شود. به جز دیتابیس بک‌اند ما stateless است. ویژگی‌های کلیدی سرویس‌های stateless عبارتند از:
- قابلیت مقیاس‌پذیری (Scalability): سرویس‌های stateless به دلیل عدم وابستگی به وضعیت مشترک، بسیار قابل مقیاس‌پذیر هستند. هر درخواست می‌تواند به صورت مستقل پردازش شود، که امکان مقیاس‌پذیری را با اضافه کردن نمونه‌های بیشتر از سرویس فراهم می‌کند.
- استحکام (Resilience): از آنجا که سرویس‌های stateless هیچ وضعیتی را ذخیره نمی‌کنند، می‌توانند به راحتی از خرابی‌ها بهبود یابند. اگر یک نمونه سرویس خراب شود، درخواست‌ها می‌توانند به نمونه‌های دیگر هدایت شوند بدون هیچ تأثیری بر روی سامانه کلی.
- انعطاف‌پذیری (Flexibility): سرویس‌های stateless می‌توانند به راحتی جایگزین یا ارتقا داده شوند بدون تأثیر بر روی سامانه کلی. نمونه‌های جدید می‌توانند مستقر شوند و نمونه‌های قدیمی می‌توانند خارج شوند بدون هیچ تأثیری بر تجربه کاربر.
